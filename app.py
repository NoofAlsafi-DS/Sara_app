# -*- coding: utf-8 -*-
import os
import pickle
import numpy as np
import streamlit as st
from scipy.sparse import hstack, csr_matrix

# ===== Extracted from notebook =====
import re, ipaddress, numpy as np
from scipy.sparse import csr_matrix, hstack
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.feature_extraction.text import TfidfVectorizer

class URLFeatureExtractor(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.suspicious_words = ["login","verify","update","secure","account","free","win","bonus","gift","bank","paypal"]
        self.shorteners = ["bit.ly","goo.gl","tinyurl","t.co","ow.ly"]
    def is_ip(self, host):
        import ipaddress
        try: ipaddress.ip_address(host); return 1
        except: return 0
    def get_host(self, url):
        m = re.match(r"https?://([^/]+)", str(url).lower())
        return m.group(1) if m else ""
    def fit(self, X, y=None): return self
    def transform(self, X):
        feats=[]
        for u in X:
            u=str(u); host=self.get_host(u); q=u.split("?",1)[1] if "?" in u else ""; params=q.split("&") if q else []
            feats.append([
                len(u), len(host), u.count("."), u.count("-"), u.count("@"), u.count("?"),
                u.count("="), u.count("%"), u.count("&"), len(params),
                1 if u.lower().startswith("https://") else 0,
                self.is_ip(host),
                1 if any(s in u.lower() for s in self.shorteners) else 0,
                1 if any(w in u.lower() for w in self.suspicious_words) else 0
            ])
        return csr_matrix(np.array(feats, dtype=float))

tfidf = TfidfVectorizer(analyzer="char", ngram_range=(3,5), min_df=2)
# ===================================

@st.cache_resource(show_spinner=False)
def load_artifacts():
    with open("model.pkl","rb") as f:
        clf = pickle.load(f)
    with open("tfidf.pkl","rb") as f:
        tfidf = pickle.load(f)
    with open("manual.pkl","rb") as f:
        man = pickle.load(f)
    return clf, tfidf, man

def get_positive_prob(model, X):
    if hasattr(model, "predict_proba"):
        proba = model.predict_proba(X)
        if proba is not None and proba.ndim == 2 and proba.shape[1] >= 2:
            return float(proba[0, 1])
    if hasattr(model, "decision_function"):
        val = model.decision_function(X)
        if np.ndim(val) == 1:
            return float(1.0 / (1.0 + np.exp(-val[0])))
    return None

st.set_page_config(page_title="ğŸ”’ URL Malware Detector", page_icon="ğŸ›¡ï¸", layout="centered")
st.title("ğŸ”’ URL Malware Detector")
st.caption("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¶Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TF-IDF + Ù…ÙŠØ²Ø§Øª ÙŠØ¯ÙˆÙŠØ© + Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¯Ø±Ù‘Ø¨.")

# Sidebar examples
with st.sidebar:
    st.subheader("Ø£Ù…Ø«Ù„Ø© Ø¬Ø§Ù‡Ø²Ø©")
    col_a, col_b = st.columns(2)
    with col_a:
        if st.button("ğŸ”— Ù…Ø«Ø§Ù„ Ù…ÙˆÙ‚Ø¹ Ø³Ù„ÙŠÙ…", use_container_width=True):
            st.session_state['sample_url'] = "https://www.wikipedia.org/"
    with col_b:
        if st.button("âš ï¸ Ù…Ø«Ø§Ù„ Ù…ÙˆÙ‚Ø¹ Ø¶Ø§Ø±", use_container_width=True):
            st.session_state['sample_url'] = "http://paypal.com.security-alert.example.com/confirm%20info"
    st.caption("Ø§Ø¶ØºØ· Ø²Ø±Ù‹Ø§ Ù„Ù…Ù„Ø¡ Ø§Ù„Ø­Ù‚Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.")

# Default text uses session value if present
default_text = st.session_state.get('sample_url', 'https://www.wikipedia.org/')
url = st.text_input("Ø£Ø¯Ø®Ù„ Ø§Ù„Ø±Ø§Ø¨Ø· Ù‡Ù†Ø§:", value=default_text, placeholder="https://example.com/path?...")

# ===== Ø£Ù…Ø«Ù„Ø© Ø¬Ø§Ù‡Ø²Ø© =====
with st.sidebar:
    st.subheader("Ø£Ù…Ø«Ù„Ø© Ø¬Ø§Ù‡Ø²Ø©")
    if st.button("ğŸ”— Ù…Ø«Ø§Ù„ Ù…ÙˆÙ‚Ø¹ Ø³Ù„ÙŠÙ…"):
        st.session_state['sample_url'] = "https://www.wikipedia.org/"
    if st.button("âš ï¸ Ù…Ø«Ø§Ù„ Ù…ÙˆÙ‚Ø¹ Ø¶Ø§Ø±"):
        st.session_state['sample_url'] = "http://paypal.com.security-alert.example.com/confirm%20info"

default_text = st.session_state.get('sample_url', 'https://www.wikipedia.org/')
url = st.text_input("Ø£Ø¯Ø®Ù„ Ø§Ù„Ø±Ø§Ø¨Ø· Ù‡Ù†Ø§:", value=default_text, placeholder="https://example.com/path?...")

if st.button("ØªØ­Ù„ÙŠÙ„ ğŸ”", type="primary") and url.strip():
    clf, tfidf, man = load_artifacts()

    # Ø­ÙˆÙ‘Ù„ Ø§Ù„Ø±Ø§Ø¨Ø·
    X_tfidf = tfidf.transform([url])
    try:
        X_manual = man.transform([url])
    except Exception as e:
        st.error("ØªØ¹Ø°Ø± ØªØ·Ø¨ÙŠÙ‚ URLFeatureExtractor.transform â€” ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚.")
        st.exception(e)
        st.stop()

    X = hstack([X_tfidf, X_manual])

    # ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª
    expected = getattr(clf, "n_features_in_", None)
    if expected is not None and X.shape[1] != expected:
        diff = expected - X.shape[1]
        st.warning(f"ØªØµØ­ÙŠØ­ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª: Ø§Ù„Ø­Ø§Ù„ÙŠ = {X.shape[1]}, Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ = {expected}.")
        if diff > 0:
            pad = csr_matrix((X.shape[0], diff))
            X = hstack([X, pad])
        else:
            X = X[:, :expected]

    pred = int(clf.predict(X)[0])
    prob = get_positive_prob(clf, X)

    if pred == 1:
        st.error("Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ø¶Ø§Ø± âŒ")
    else:
        st.success("Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ø³Ù„ÙŠÙ… âœ…")

    if prob is not None:
        st.metric("Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© (Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø¶Ø§Ø±)", f"{prob:.3f}")
    else:
        st.caption("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø§ ÙŠØ¯Ø¹Ù… `predict_proba`.")

st.markdown("---")
st.caption("Â© 2025 â€” Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ ÙÙ‚Ø·.")
